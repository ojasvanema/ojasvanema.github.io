---
layout: about
title: about
permalink: /
subtitle: Undergraduate Researcher at <a href='https://www.iitr.ac.in/'>IIT Roorkee</a>.

profile:
  align: right
  image: profile_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Department of Metallurgical and Materials Engineering</p>
    <p>IIT Roorkee, India</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Hi, I'm **Ojasva**.

I am an undergraduate at **IIT Roorkee** . My work revolves around **Deep Generative Models**, **Mechanistic Interpretability**, and **Large Language Models**.

Currently, my work is focused on **Mechanistic Interpretability**. I am an active member of the **Data Science Group (DSG)**, a student club on campus. I lead a research squad within the club, investigating LLM internals. We recently published work on how models route domain knowledge (check our [website](#)).


Simultaneously, I work at the **P-square Lab** with [Prof. Parikshit Pareek](https://www.iitr.ac.in/~EE/Parikshit_Pareek). We are currently investigating **Bilinear MLPs** to find more interpretable architectures and building a **foundation model for amortized kernel hyperparameter discovery**. We also recently finalized a **Sparse Diffusion** framework for high-energy physics (CERN).

Previously, I worked on **Image Alchemy**, a personalization method for diffusion models that I published at **ICLR 2025**.

Beyond the lab, I recently gained real-world experience at **Elimentary**, where I engineered local LLM APIs and evaluation pipelines.


Always happy to chat about circuits, LLMs or whatâ€™s next in AI!
What would you do if you had infinte compute?